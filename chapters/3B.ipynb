{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DICOM, HL7 and FHIR"
      ],
      "metadata": {
        "id": "56V5DMyPkVl7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Author: Bradley J. Erickson, MD PhD FSIIM*"
      ],
      "metadata": {
        "id": "mAWG0GVPbvfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DICOM"
      ],
      "metadata": {
        "id": "mUBLK3W1kRSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DICOM stands for Digital Imaging and Communications in Medicine. It is a standard format used for storing and transmitting medical images such as X-rays, CT scans, and MRIs. DICOM files contain both image data and metadata, which includes information about the patient, the imaging equipment used, and the imaging procedure itself.\n",
        "DICOM images are used in medical image processing tasks such as segmentation, registration, and classification. Segmentation is the process of separating an image into multiple regions or objects. Registration is the process of aligning two or more images of the same subject taken at different times or with different imaging modalities. Classification is the process of assigning a label to an image based on its content.\n",
        "Pydicom is a Python library that provides an easy-to-use interface for working with DICOM files. It allows you to read, modify, and write DICOM files using Python code. Pydicom provides access to important information elements such as patient name, patient ID, study date, study time, modality, and more. Here’s an example code snippet that demonstrates how to use pydicom to access these information elements:\n"
      ],
      "metadata": {
        "id": "vO9URZRMOdJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run this cell to load the data and setup packages. { vertical-output: true, display-mode: \"form\" }\n",
        "# @markdown *This might take a few seconds*.\n",
        "# @markdown\n",
        "# @markdown After running this cell we have:\n",
        "# @markdown *   `MIDEL-CT.dcm`: a test DICOM image.\n",
        "# @markdown *   `pydicom` package: used for DICOM image processing.\n",
        "# @markdown *   `hl7` package: used for HL7 message parsing.\n",
        "\n",
        "import gdown\n",
        "gdown.download(\n",
        "    \"https://drive.google.com/uc?export=download&confirm=pbef&id=1S1zfz_UVYpf1fuzOlbiXNDpRGm6k9RPL\",\n",
        "    \"MIDEL-CT.dcm\",\n",
        "    quiet=True,\n",
        ")\n",
        "!pip install pydicom hl7 -q"
      ],
      "metadata": {
        "id": "OL_shCRVdN3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2fc2f0-4801-410b-915b-c6c5ce6823e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.8 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.4/1.8 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrZG3hL3OUi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6933f844-d12e-4d25-d80c-0f4a860489bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Patient Name: MIDEL, patientname\n",
            "Patient ID: MIDEL1234\n",
            "Study Date: \n",
            "Study Time: \n",
            "Modality: CT\n"
          ]
        }
      ],
      "source": [
        "import pydicom\n",
        "\n",
        "# Load a DICOM file\n",
        "ds = pydicom.dcmread('./MIDEL-CT.dcm')\n",
        "\n",
        "# Access important information elements\n",
        "patient_name = ds.PatientName\n",
        "patient_id = ds.PatientID\n",
        "study_date = ds.StudyDate\n",
        "study_time = ds.StudyTime\n",
        "modality = ds.Modality\n",
        "\n",
        "# Print the information elements\n",
        "print(f'Patient Name: {patient_name}')\n",
        "print(f'Patient ID: {patient_id}')\n",
        "print(f'Study Date: {study_date}')\n",
        "print(f'Study Time: {study_time}')\n",
        "print(f'Modality: {modality}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are fairly straightforward and DICOM clearly specifies the format for representing date, time, and modality. The size and orientation of the pixels is a bit more complex--lets take a look.\n"
      ],
      "metadata": {
        "id": "i5LXIG6qOj_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access important information elements\n",
        "slice_thickness = ds.SliceThickness\n",
        "pixel_spacing = ds.PixelSpacing\n",
        "image_orientation = ds.ImageOrientationPatient\n",
        "\n",
        "# Print the information elements\n",
        "print(f'Slice Thickness: {slice_thickness}')\n",
        "print(f'Pixel Spacing: {pixel_spacing}')\n",
        "print(f'Image Orientation: {image_orientation}')\n"
      ],
      "metadata": {
        "id": "MqP0oYSPOqn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374337bb-0114-4e13-8417-175c14a5d2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slice Thickness: 5.000000\n",
            "Pixel Spacing: [0.488281, 0.488281]\n",
            "Image Orientation: [1.000000, 0.000000, 0.000000, 0.000000, 0.996917, -0.078459]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The slice thickness makes sense, and is always in millimeters, and is the distance from the ‘top’ of the slice to the ‘bottom’. Note this is **not** always the same as the slice spacing! Because DICOM is usually a one-slice at a time data object, one must do much more work to figure out slice spacing since it is the distance between two slices. While it is common for all the slices in a series to have (*nearly*) the same spacing, that is not required, and was not as common in the early days of CT imaging.\n",
        "\n",
        "And since DICOM file names do not necessarily correlate with their position, you must go through each file and sort them into slice position order and then figure out the spacing. That sounds simple, but again is not quite so easy since the slice position is (usually) a string with a letter indicating ‘L’, ‘R’,  ‘A’, ’P’, ’S’, or ‘I’, and then a number indicating how (in millimeters) far left or right or anterior, etc., it is from isocenter.\n",
        "\n",
        "\n",
        "While slice thickness refers to the edges of the voxel, the pixel dimensions refer to the spacing between pixels in the X and Y dimensions, and DICOM does expect the spacing to be constant for this image. (There are exceptions for modalities like ultrasound where there can be an 'inset' image with a different magnification).\n",
        "\n",
        "Now that we know about the size of the pixels, what about the orientation? Many imaging devices can acquire an image in almost any plane, but CT scanners nearly always (now) acquire axial images, and other planes are reconstructed from that. MRI is more variable, and for many organs, the images are acquired in an oblique orientation.\n",
        "\n",
        "Briefly about orientation names: ‘axial’ (also called ‘transverse’ or ‘transaxial’) means an image that is perpendicular to the long axis of the body. Furthermore, its left and right (‘X’) axis is also the left and right axis of the object being imaged, and the ‘Y’ axis of the image is considered to be in the anterior-posterior direction. A ‘Coronal’ image gets its name from the coronal suture of the skull, which is at the top of the head and is a plane that is like facing the patient: the ‘X’ axis of the image is also the ‘X’ axis of the patient, but the ‘Y’ axis of the image is the ‘Z’ axis (inferior-superior) of the patient. Sagittal gets its name from the sagittal suture, which is the connection between the left and right halves of the skull. Therefore, its ‘X’ axis is the anterior-posterior line of the patient, and its ‘Y’ axis is the  ‘Z’ axis of the patient.\n",
        "\n",
        "<br><img src=\"https://i.ibb.co/gT17Qkb/orientation.jpg\" alt=\"Figure 1\" style='margin:auto' border=\"0\"><br><u>\n",
        "<b>Figure 1.</b> Different image orientations.</u><br><br>\n",
        "\n",
        "The relationship between moving 1 pixel along the ‘X’ axis of the image is thus represented as 3 floating point values: the change in ‘X’ of the <u>patient</u>, the change in ‘Y’ of the <u>patient</u>, and the change in ‘Z’ of the <u>patient</u>. Similarly, there is another set of 3 values for showing the change as one moves along the ‘Y’ axis of the image, again representing the ‘X’, ‘Y’, and ‘Z’ change in the patient. This set of 6 values completely defines the orientation of the image, and they are known as directional cosines. In this case, the (1.0,0.0,0.0) means that the X-direction of the image moves 1.0 along the X-axis of the patient and 0 in the Y and Z axes. The second set of 3 numbers (0.0, 0.996, -0.078) means it moves 0 along the patient X axis, almost 1 (0.996) along the Y-axis, and just a little bit negative along the patient Z axis as we move along Y in the image (-0.078). From these, one can compute the orientation of the slice:\n"
      ],
      "metadata": {
        "id": "JM1TX5dAOzCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def getMajorAxisFromDirCos(x, y, z):\n",
        "    axis = \"\"\n",
        "    if (x < 0):\n",
        "        XOrient = \"R\"\n",
        "    else:\n",
        "        XOrient = \"L\"\n",
        "    if (y < 0):\n",
        "        YOrient = \"A\"\n",
        "    else:\n",
        "        YOrient = \"P\"\n",
        "    if (z < 0):\n",
        "        ZOrient = \"F\"\n",
        "    else:\n",
        "        ZOrient = \"H\"\n",
        "\n",
        "    absX = math.fabs(x)\n",
        "    absY = math.fabs(y)\n",
        "    absZ = math.fabs(z)\n",
        "\n",
        "    if ((absX > 0.25) and (absX > absY) and (absX > absZ)):\n",
        "        axis = XOrient\n",
        "    elif ((absY > 0.25) and (absY > absX) and (absY > absZ)):\n",
        "        axis = YOrient\n",
        "    elif ((absZ > 0.25) and (absZ > absX) and (absZ > absY)):\n",
        "        axis = ZOrient\n",
        "    return axis\n",
        "\n",
        "\n",
        "def getImageOrientFromDirCos(rowX, rowY, rowZ, colX, colY, colZ):\n",
        "    label = \"\"\n",
        "    rowAxis = getMajorAxisFromDirCos(rowX, rowY, rowZ)\n",
        "    colAxis = getMajorAxisFromDirCos(colX, colY, colZ)\n",
        "\n",
        "    if (rowAxis != \"\" and colAxis != \"\"):\n",
        "        if ((rowAxis == \"R\" or rowAxis == \"L\") and (colAxis == \"A\" or colAxis == \"P\")):\n",
        "            label = \"AXL (Axial)\"\n",
        "        if ((rowAxis == \"R\" or rowAxis == \"L\") and (colAxis == \"A\" or colAxis == \"P\")):\n",
        "            label = \"AXL (Axial)\"\n",
        "\n",
        "        if ((rowAxis == \"R\" or rowAxis == \"L\") and (colAxis == \"H\" or colAxis == \"F\")):\n",
        "            label = \"COR (Coronal)\"\n",
        "        if ((rowAxis == \"R\" or rowAxis == \"L\") and (colAxis == \"H\" or colAxis == \"F\")):\n",
        "            label = \"COR (Coronal)\"\n",
        "\n",
        "        if ((rowAxis == \"A\" or rowAxis == \"P\") and (colAxis == \"H\" or colAxis == \"F\")):\n",
        "            label = \"SAG (Saggital)\"\n",
        "        if ((rowAxis == \"A\" or rowAxis == \"P\") and (colAxis == \"H\" or colAxis == \"F\")):\n",
        "            label = \"SAG (Saggital)\"\n",
        "    else:\n",
        "        label = \"OBL (Oblique)\"\n",
        "    return label\n",
        "\n",
        "ImageOrientDirCos = ds.ImageOrientationPatient\n",
        "Orient = getImageOrientFromDirCos(ImageOrientDirCos[0], ImageOrientDirCos[1], ImageOrientDirCos[2],\n",
        "                                  ImageOrientDirCos[3], ImageOrientDirCos[4], ImageOrientDirCos[5])\n",
        "\n",
        "print (\"Image Orientation:\", Orient)\n"
      ],
      "metadata": {
        "id": "GojWfVbvO0Sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d13e42e-3c39-4a25-aa9a-1c6d68aaaf02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Orientation: AXL (Axial)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DICOM is probably most similar to the TIFF image file format, in that it has many 'tags' at the start of the file that describe the image, and then the end of the file is the actual pixel information. Tags include information such as demographic details about the patient, imaging study’s acquisition parameters, image dimensions, matrix size, color space, and more. This makes it easier to manage and exchange medical images between different devices from multiple manufacturers.\n",
        "\n",
        "There are 2 ways to identify a tag: using a pair of 4-digit hexadecimal numbers (not so user friendly) or by using text labels, where the labels come from a dictionary so you must use those exact labels. The DICOM standard group numbers (the first number of the pair) are even numbers. One can have (non-standard) tags in a DICOM file that have odd numbers. These are called 'Private Tags' and their content and meaning are defined by the creator. This allows vendors to store information relevant to an image in cases where the DICOM Committee has not defined a tag.\n",
        "\n",
        "A commonly noted example of this is for early diffusion-weighted MRI. Vendors (and researchers) created diffusion-weighted images and the information (like B-value) was usually stored in private tags, but each vendor stored this informatoin in the private tag they defined (and this sometimes changed with different software versions). Once the community is using an image type enough, the DICOM Committee will create a working group that will define what the tags should be and they then become a part of the standard tag set. Then the vendors must update their scanner software to reflect this.\n",
        "\n",
        "There is a HUGE amount of information about an image in the tags, particularly for CT and MR images. A great site for looking up DICOM tags is: http://dicomlookup.com/ or https://dicom.innolitics.com/."
      ],
      "metadata": {
        "id": "rqXTa160PT2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HL7"
      ],
      "metadata": {
        "id": "5DEpsuAbkx_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HL7 stands for 'Health Level Seven' where the '7' refers to an old IT concept that there are 7 layers of information systems from the low level (e.g. the packets transferred between computers) up to the highest level which is concepts. It is a set of international standards for the exchange, integration, sharing, and retrieval of electronic health information. These standards are specifically designed for the healthcare industry to facilitate the interoperability of health information systems. HL7 standards are widely used to enable the seamless communication and data exchange between various healthcare systems, including electronic health records (EHRs), laboratory information systems, pharmacy systems, and more.\n",
        "\n",
        "A few key aspects to remeber about HL7:\n",
        "\n",
        "**Versions:** HL7 defines messaging standards, such as HL7 Version 2 (HL7 v2) and HL7 Version 3 (HL7 v3), which specify the format and content of messages exchanged between healthcare applications. HL7 v2 is widely used for its simplicity and widespread adoption, while HL7 v3 offers more semantic interoperability but is less commonly used.\n",
        "\n",
        "**Clinical Document Architecture (CDA):** HL7 CDA is a standard for creating and sharing clinical documents, such as discharge summaries and progress notes, in a structured format. CDA documents are XML-based and can be easily exchanged between different EHR systems.\n",
        "\n",
        "**Terminology Standards:** HL7 incorporates standard terminologies like SNOMED CT, LOINC, and RxNorm to ensure consistency in coding and describing clinical data. This helps in semantic interoperability and accurate data exchange.\n",
        "\n",
        "**Integration with Healthcare IT Systems:** HL7 standards are used for integrating various healthcare IT systems, including EHRs, laboratory systems, radiology information systems, and more. This integration helps healthcare organizations streamline workflows and improve patient care.\n",
        "\n"
      ],
      "metadata": {
        "id": "shwZ8-6U6vzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HL7 Message Types"
      ],
      "metadata": {
        "id": "bcpUFYQ7k0L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HL7 defines several types of messages for exchanging healthcare information. These messages serve different purposes and are used in various healthcare scenarios. Some of the most common types of HL7 messages include:\n",
        "\n",
        "1. **ADT (Admit, Discharge, Transfer) Messages (HL7 v2.3 and later):** These messages are used for patient demographic and visit information, including admissions, discharges, and transfers. They provide details about a patient's admission to or discharge from a healthcare facility and any changes in their demographic information.\n",
        "\n",
        "2. **ORM (Order Message) and ORU (Observation Result Message) Messages (HL7 v2.3 and later):** ORM messages are used to transmit orders for laboratory tests, procedures, or medications. ORU messages, on the other hand, convey the results of these orders, such as lab results, diagnostic reports, or imaging studies.\n",
        "\n",
        "3. **SIU (Scheduling Information Unsolicited) Messages (HL7 v2.3 and later):** These messages contain unsolicited scheduling information, such as appointment notifications, cancellations, and rescheduling updates.\n",
        "\n",
        "4. **MDM (Medical Document Management) Messages (HL7 v2.3 and later):** MDM messages are used for the exchange of medical documents, including clinical reports, discharge summaries, and other clinical documents.\n",
        "\n",
        "5. **ADT^Axx (ADT Acknowledgment) Messages (HL7 v2.3 and later):** These acknowledgment messages are sent in response to ADT messages and provide confirmation or notification of errors or exceptions.\n",
        "\n",
        "6. **QRY (Query) Messages (HL7 v2.3 and later):** QRY messages are used for querying patient data or other information from a remote system. They can be used to request patient demographic information, clinical data, or other relevant data.\n",
        "\n",
        "7. **RSP (Response) Messages (HL7 v2.3 and later):** RSP messages are sent in response to QRY messages and contain the requested data or information.\n",
        "\n",
        "8. **MFN (Master File Notification) Messages (HL7 v2.3 and later):** These messages are used to update master files, such as patient or provider records, by notifying other systems of changes or updates.\n",
        "\n",
        "9. **BAR (Billing Account Record) Messages (HL7 v2.3 and later):** BAR messages are used for financial transactions and billing-related information, such as insurance claims and invoices.\n",
        "\n",
        "10. **MFQ (Master File Query) Messages (HL7 v2.3 and later):** These messages are used to query master files, such as patient or provider records, to retrieve specific information.\n",
        "\n",
        "11. **MFQ/MFR (Master File Query/Response) Messages (HL7 v2.5 and later):** MFQ/MFR messages combine querying and responding to master file information in a single message exchange.\n",
        "\n",
        "12. **VXU (Vaccination Update) Messages (HL7 v2.3.1 and later):** VXU messages are used for the exchange of vaccination and immunization data, including patient vaccination histories.\n",
        "\n",
        "13. **PPR (Patient Problem) Messages (HL7 v2.5 and later):** PPR messages convey information about patient problems, such as medical conditions, allergies, and other health concerns.\n",
        "\n",
        "These are some of the key HL7 message types used in healthcare interoperability. The choice of message type depends on the specific information being exchanged and the purpose of the communication within the healthcare system. Different versions of HL7 (e.g., HL7 v2.x, HL7 v3, and HL7 FHIR) have variations in message types and structures to accommodate evolving healthcare needs and technology advancements."
      ],
      "metadata": {
        "id": "3o9zbTTr8V3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HL7 Message Segements"
      ],
      "metadata": {
        "id": "SCXR1BYBk-9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HL7 message segments are fundamental building blocks of HL7 messages. These segments serve as containers for specific types of information within an HL7 message. Each segment has a predefined structure and a two-to-four-letter code that identifies its purpose and the type of data it contains. Here are some common HL7 message segments:\n",
        "\n",
        "1. **MSH (Message Header):** The MSH segment is the first segment in an HL7 message. It contains information about the message itself, such as the message type, source, destination, and timestamps. It helps in routing and processing the message correctly.\n",
        "\n",
        "2. **PID (Patient Identification):** The PID segment contains patient demographic information, including patient ID, name, date of birth, sex, and other patient-specific details. It is essential for accurately identifying and managing patient records.\n",
        "\n",
        "3. **PV1 (Patient Visit Information):** The PV1 segment provides information about the patient's visit to a healthcare facility. It includes data such as admission and discharge dates, visit number, patient class, and attending physician.\n",
        "\n",
        "4. **ORC (Common Order):** The ORC segment is used in order-related messages (e.g., ORM) and contains information about orders, including order control codes, ordering provider, and order status.\n",
        "\n",
        "5. **OBR (Observation Request):** The OBR segment is used to request clinical observations or tests. It includes details such as the test name, specimen source, and relevant clinical information.\n",
        "\n",
        "6. **OBX (Observation Result):** The OBX segment carries the results of clinical observations or tests requested in the OBR segment. It includes the observed value, units of measurement, reference ranges, and interpretation codes.\n",
        "\n",
        "7. **NK1 (Next of Kin):** The NK1 segment contains information about the patient's next of kin or emergency contacts, including their names, relationships, and contact details.\n",
        "\n",
        "8. **DG1 (Diagnosis):** The DG1 segment is used to convey diagnostic information, such as patient diagnoses, admitting diagnoses, and diagnosis codes (e.g., ICD-10 codes).\n",
        "\n",
        "9. **RXA (Pharmacy/Treatment Administration):** The RXA segment is used in medication administration messages (e.g., ADT) to convey details about medication administration, including drug name, dose, route, and administration date/time.\n",
        "\n",
        "10. **GT1 (Guarantor):** The GT1 segment contains information about the patient's financial guarantor or responsible party, including their names, addresses, and insurance information.\n",
        "\n",
        "11. **IN1 (Insurance):** The IN1 segment includes details about the patient's insurance coverage, such as insurance plan name, policy number, and eligibility information.\n",
        "\n",
        "12. **Z-Segments (User-Defined Segments):** Z-segments are user-defined segments that allow for the inclusion of custom or site-specific data within an HL7 message. Healthcare organizations can use these segments to exchange additional information specific to their needs. These are analogous to DICOM's private tags."
      ],
      "metadata": {
        "id": "5SqevAl-_GKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is one example of an ORM HL7 message:\n",
        "\n",
        "```\n",
        "MSH|^~&|HIS|MIDELMedCenter|RIS|MIDELMedCenter|20160307110114||ORM^O01|MSGID20060307110114|P|2.3\\r\n",
        "PID|||12001||Smith^John^^^Mr.||19570824|M|||123 West St.^^Minneapolis^MN^55431^USA|||||||\\r\n",
        "PV1||O|OP^PAREG^||||2342^Johnson^Bob|||OP|||||||||2|||||||||||||||||||||||||20160307110111|\\r\n",
        "ORC|NW|20160307110114\\r\n",
        "OBR|1|20160307110114||003038^Chest Radiograph^L|||20160307110114\\r\n",
        "```\n",
        "\n",
        "Let's parse this message:"
      ],
      "metadata": {
        "id": "AYgu0w2wk9Gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hl7\n",
        "\n",
        "# HL7 message as a string\n",
        "message = \"MSH|^~&|HIS|MIDELMedCenter|RIS|MIDELMedCenter|20160307110114||ORM^O01|MSGID20060307110114|P|2.3\\r\" + \\\n",
        "          \"PID|||12001||Smith^John^^^Mr.||19570824|M|||123 West St.^^Minneapolis^MN^55431^USA|||||||\\r\" +  \\\n",
        "          \"PV1||O|OP^PAREG^||||2342^Johnson^Bob|||OP|||||||||2|||||||||||||||||||||||||20160307110111|\\r\" + \\\n",
        "          \"ORC|NW|20160307110114\\r\" + \\\n",
        "          \"OBR|1|20160307110114||003038^Chest Radiograph^L|||20160307110114\\r\"\n",
        "\n",
        "parsed_message = hl7.parse(message)\n",
        "\n",
        "print(\"Number of segments:\",len(parsed_message))\n",
        "print(\"OBR segment is parsed as:\")\n",
        "print(parsed_message.segments(\"OBR\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_FtsfP3lPZn",
        "outputId": "6e22620f-ecf6-44b8-9a23-2cabe1985d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of segments: 5\n",
            "OBR segment is parsed as:\n",
            "[[['OBR'], ['1'], ['20160307110114'], [''], [[['003038'], ['Chest Radiograph'], ['L']]], [''], [''], ['20160307110114']]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, there is no easy way to understand what each value represents. These are just some examples of HL7 message segments. The choice of segments used in an HL7 message depends on the message type and the specific information being exchanged. Healthcare informatics professionals need to be familiar with the structure and purpose of these segments to effectively process and interpret HL7 messages, ensuring accurate and meaningful healthcare data exchange."
      ],
      "metadata": {
        "id": "91GZMqfclFyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fast Healthcare Interoperability Resources (FHIR)"
      ],
      "metadata": {
        "id": "xDwPhezulLdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FHIR is a modern healthcare interoperability standard developed by Health Level Seven International (HL7) starting in 2016, due to challenges around HL7, particuarly querying information, but also the desire to have a protocol using modern IT technologies. FHIR is designed to address the challenges of exchanging healthcare data in a more efficient, flexible, and standardized manner. It has gained significant attention and adoption within the healthcare informatics field due to its innovative approach.\n",
        "\n",
        "FHIR is based on modern web standards like RESTful APIs (Representational State Transfer) and uses widely adopted data formats like JSON and XML for data exchange. This approach makes it developer-friendly and accessible for software applications and web services. It follows the \"resource\" model, where healthcare data is represented as resources with standardized data elements and relationships. Resources can represent various healthcare entities, such as patients, providers, medications, and observations.\n",
        "FHIR emphasizes granular data exchange. Instead of sending large, complex documents, it allows the exchange of individual data elements or resources. This granularity enables precise data retrieval and efficient updates.\n",
        "\n",
        "FHIR defines a set of standardized resources, each representing a specific aspect of healthcare data. For example, the \"Patient\" resource contains demographic information, while the \"Observation\" resource represents clinical observations like lab results or vital signs. Each resource has a well-defined structure with common data elements (attributes) and relationships to other resources.\n",
        "\n",
        "FHIR allows for extensibility by enabling the addition of custom data elements or extensions to existing resources. This flexibility accommodates local or specialized data requirements. This can lead to challenges if you don't know the definitions of these added messages.\n",
        "\n",
        "For example, for the previous HL7 message, the OBR segment can be reorderd as the following FHIR message:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"resourceType\": \"DiagnosticReport\",\n",
        "  \"id\": \"20160307110114\",\n",
        "  \"status\": \"final\",\n",
        "  \"code\": {\n",
        "    \"coding\": [\n",
        "      {\n",
        "        \"system\": \"http://loinc.org\",\n",
        "        \"code\": \"003038\",\n",
        "        \"display\": \"Chest Radiograph\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  \"subject\": {\n",
        "    \"reference\": \"Patient/12001\"\n",
        "  },\n",
        "  \"effectiveDateTime\": \"2016-03-07T11:01:14\",\n",
        "  \"issued\": \"2016-03-07T11:01:14\"\n",
        "}\n",
        "```\n",
        "\n",
        "The FHIR implementation guides provide detailed specifications and profiles for specific use cases, specialties, or regions. These guides help standardize data exchange in specialized contexts.\n",
        "\n",
        "In summary, FHIR is a groundbreaking standard in healthcare informatics that addresses the need for flexible, efficient, and standardized data exchange in the digital healthcare landscape. Its adoption continues to grow, and it plays a crucial role in achieving healthcare interoperability, supporting innovation in healthcare applications, and improving patient care."
      ],
      "metadata": {
        "id": "wrg5Pjkt9EyA"
      }
    }
  ]
}